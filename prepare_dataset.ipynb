{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0792412e",
      "metadata": {},
      "source": [
        "# Dataset Preparation for YOLOv11 and Detectron2 (Per-Letter Training)\n",
        "\n",
        "This notebook prepares a unified dataset for:\n",
        "\n",
        "- **YOLOv11 (Ultralytics)** object detection with **multi-class letters** (all letters in one dataset, trainable per letter via `classes=[...]`).\n",
        "- **Detectron2**, also trained **per-letter**, i.e. one Detectron2 model per letter using filtered single-letter COCO annotations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aef7b38e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COCO_PATH: /home/suliman/midrash_auto_annotate_asc/annotations/annotations.json\n",
            "IMAGES_ROOT: /home/suliman/midrash_auto_annotate_asc/images\n",
            "TARGET_ROOT: /home/suliman/midrash_auto_annotate_asc/ASC_dataset2\n",
            "Total images in original COCO: 53\n",
            "Images found on disk:          37\n",
            "Images missing on disk:        16\n",
            "Example missing files (up to 10): ['003_000_00.jpg', '030_000_00.jpg', '030_000_01.jpg', '030_000_02.jpg', '036_000_02.jpg', '034_000_01.jpg', '035_000_00.jpg', '035_000_02.jpg', '035_000_03.jpg', '034_000_00.jpg']\n",
            "Total annotations (original):  10063\n",
            "Annotations kept:              6379\n",
            "Categories kept:               6\n",
            "Cleaned COCO written to:       ASC_dataset2/annotations_clean.json\n",
            "COCO_PATH updated to: ASC_dataset2/annotations_clean.json\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# ==== CONFIGURATION ====\n",
        "# Path to the original COCO annotations file (multi-class letters)\n",
        "COCO_PATH = Path(\"annotations/annotations.json\")\n",
        "\n",
        "# Root directory of the original images with script modes as subfolders\n",
        "#   images_root/\n",
        "#       french/...\n",
        "#       german/...\n",
        "IMAGES_ROOT = Path(\"images\")\n",
        "\n",
        "# Target root directory for the prepared dataset\n",
        "TARGET_ROOT = Path(\"ASC_dataset2\")\n",
        "\n",
        "# Validation split ratio\n",
        "VAL_RATIO = 0.2  # 20% for validation\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "TARGET_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"COCO_PATH: {COCO_PATH.resolve()}\")\n",
        "print(f\"IMAGES_ROOT: {IMAGES_ROOT.resolve()}\")\n",
        "print(f\"TARGET_ROOT: {TARGET_ROOT.resolve()}\")\n",
        "\n",
        "\n",
        "# === OPTIONAL CLEANING STEP ===\n",
        "\n",
        "CLEAN_COCO_PATH = Path(TARGET_ROOT / \"annotations_clean.json\")  # new, cleaned file\n",
        "IMAGES_ROOT = Path(\"images\")                          # with images/french, images/german\n",
        "\n",
        "\n",
        "def clean_coco_missing_images(raw_coco_path: Path,\n",
        "                              images_root: Path,\n",
        "                              out_coco_path: Path):\n",
        "    \"\"\"\n",
        "    Remove images and annotations from a COCO file if the image file\n",
        "    no longer exists on disk (in images/french or images/german).\n",
        "\n",
        "    Also drops categories that are no longer used.\n",
        "    \"\"\"\n",
        "    with raw_coco_path.open(\"r\") as f:\n",
        "        coco = json.load(f)\n",
        "\n",
        "    images = coco[\"images\"]\n",
        "    annotations = coco[\"annotations\"]\n",
        "    categories = coco[\"categories\"]\n",
        "\n",
        "    def image_exists(fname: str) -> bool:\n",
        "        # We search for the filename under both script modes\n",
        "        for script_mode in [\"french\", \"german\"]:\n",
        "            p = images_root / script_mode / fname\n",
        "            if p.exists():\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    # Keep only images that exist on disk\n",
        "    kept_images = []\n",
        "    kept_image_ids = set()\n",
        "    missing_files = []\n",
        "\n",
        "    for img in images:\n",
        "        fname = img[\"file_name\"]\n",
        "        if image_exists(fname):\n",
        "            kept_images.append(img)\n",
        "            kept_image_ids.add(img[\"id\"])\n",
        "        else:\n",
        "            missing_files.append(fname)\n",
        "\n",
        "    # Keep only annotations whose image_id is still present\n",
        "    kept_annotations = [ann for ann in annotations if ann[\"image_id\"] in kept_image_ids]\n",
        "\n",
        "    # Optionally: keep only categories that are still used\n",
        "    used_cat_ids = {ann[\"category_id\"] for ann in kept_annotations}\n",
        "    kept_categories = [cat for cat in categories if cat[\"id\"] in used_cat_ids]\n",
        "\n",
        "    cleaned_coco = {\n",
        "        \"images\": kept_images,\n",
        "        \"annotations\": kept_annotations,\n",
        "        \"categories\": kept_categories,\n",
        "    }\n",
        "\n",
        "    with out_coco_path.open(\"w\") as f:\n",
        "        json.dump(cleaned_coco, f, indent=4)\n",
        "\n",
        "    print(f\"Total images in original COCO: {len(images)}\")\n",
        "    print(f\"Images found on disk:          {len(kept_images)}\")\n",
        "    print(f\"Images missing on disk:        {len(missing_files)}\")\n",
        "    if missing_files:\n",
        "        print(\"Example missing files (up to 10):\", missing_files[:10])\n",
        "\n",
        "    print(f\"Total annotations (original):  {len(annotations)}\")\n",
        "    print(f\"Annotations kept:              {len(kept_annotations)}\")\n",
        "\n",
        "    print(f\"Categories kept:               {len(kept_categories)}\")\n",
        "    print(f\"Cleaned COCO written to:       {out_coco_path}\")\n",
        "\n",
        "\n",
        "clean_coco_missing_images(COCO_PATH, IMAGES_ROOT, CLEAN_COCO_PATH)\n",
        "\n",
        "# IMPORTANT: tell the rest of the notebook to use the cleaned file\n",
        "COCO_PATH = CLEAN_COCO_PATH\n",
        "print(\"COCO_PATH updated to:\", COCO_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "250cb6c8",
      "metadata": {},
      "source": [
        "## Step 1: Split COCO and Images into Train/Val (Preserving Script Modes)\n",
        "\n",
        "This step:\n",
        "- Loads `annotations.json`.\n",
        "- Infers the **script mode** (`french` / `german`) of each image by searching under `images/`.\n",
        "- Splits images randomly into **train** and **val** using `VAL_RATIO`.\n",
        "- Writes two COCO files under `ASC_dataset2/`:\n",
        "  - `annotations_train.json`\n",
        "  - `annotations_val.json`\n",
        "- Copies images into:\n",
        "  - `ASC_dataset2/images/train/french`, `ASC_dataset2/images/train/german`\n",
        "  - `ASC_dataset2/images/val/french`,   `ASC_dataset2/images/val/german`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "718aef7c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images: 29, Val images: 8\n",
            "Wrote: ASC_dataset2/annotations_train.json\n",
            "Wrote: ASC_dataset2/annotations_val.json\n"
          ]
        }
      ],
      "source": [
        "def split_coco_and_images(coco_path: Path,\n",
        "                          images_root: Path,\n",
        "                          target_root: Path,\n",
        "                          val_ratio: float = 0.2,\n",
        "                          seed: int = 42):\n",
        "    random.seed(seed)\n",
        "\n",
        "    with coco_path.open(\"r\") as f:\n",
        "        coco = json.load(f)\n",
        "\n",
        "    images = coco[\"images\"]\n",
        "    annotations = coco[\"annotations\"]\n",
        "    categories = coco[\"categories\"]\n",
        "\n",
        "    # Helper: find full path and script mode (french/german) for each image\n",
        "    def find_image_path(fname: str):\n",
        "        for script_mode in [\"french\", \"german\"]:\n",
        "            p = images_root / script_mode / fname\n",
        "            if p.exists():\n",
        "                return p, script_mode\n",
        "        raise FileNotFoundError(f\"Image {fname} not found under {images_root}/french or german.\")\n",
        "\n",
        "    # Attach full path and script_mode to each image entry (temporarily)\n",
        "    for img in images:\n",
        "        fname = img[\"file_name\"]\n",
        "        full_path, script_mode = find_image_path(fname)\n",
        "        img[\"__full_path\"] = str(full_path)\n",
        "        img[\"__script_mode\"] = script_mode\n",
        "\n",
        "    # Shuffle and split\n",
        "    random.shuffle(images)\n",
        "    split_idx = int(len(images) * (1.0 - val_ratio))\n",
        "    train_images = images[:split_idx]\n",
        "    val_images = images[split_idx:]\n",
        "\n",
        "    train_ids = {img[\"id\"] for img in train_images}\n",
        "    val_ids = {img[\"id\"] for img in val_images}\n",
        "\n",
        "    train_annotations = [ann for ann in annotations if ann[\"image_id\"] in train_ids]\n",
        "    val_annotations = [ann for ann in annotations if ann[\"image_id\"] in val_ids]\n",
        "\n",
        "    # Clean temp fields and build COCO dicts\n",
        "    def clean_image_list(img_list):\n",
        "        cleaned = []\n",
        "        for img in img_list:\n",
        "            img_copy = dict(img)\n",
        "            img_copy.pop(\"__full_path\", None)\n",
        "            img_copy.pop(\"__script_mode\", None)\n",
        "            cleaned.append(img_copy)\n",
        "        return cleaned\n",
        "\n",
        "    train_coco = {\n",
        "        \"images\": clean_image_list(train_images),\n",
        "        \"annotations\": train_annotations,\n",
        "        \"categories\": categories,\n",
        "    }\n",
        "    val_coco = {\n",
        "        \"images\": clean_image_list(val_images),\n",
        "        \"annotations\": val_annotations,\n",
        "        \"categories\": categories,\n",
        "    }\n",
        "\n",
        "    # Write split COCO files\n",
        "    train_json = target_root / \"annotations_train.json\"\n",
        "    val_json = target_root / \"annotations_val.json\"\n",
        "\n",
        "    with train_json.open(\"w\") as f:\n",
        "        json.dump(train_coco, f, indent=4)\n",
        "    with val_json.open(\"w\") as f:\n",
        "        json.dump(val_coco, f, indent=4)\n",
        "\n",
        "    # Create target image directories\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        for script_mode in [\"french\", \"german\"]:\n",
        "            (target_root / \"images\" / split / script_mode).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Copy images into target structure\n",
        "    def copy_images(img_list, split_name: str):\n",
        "        for img in img_list:\n",
        "            src = Path(img[\"__full_path\"])\n",
        "            script_mode = img[\"__script_mode\"]\n",
        "            dst = target_root / \"images\" / split_name / script_mode / img[\"file_name\"]\n",
        "            dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "            if not dst.exists():\n",
        "                shutil.copy2(src, dst)\n",
        "\n",
        "    copy_images(train_images, \"train\")\n",
        "    copy_images(val_images, \"val\")\n",
        "\n",
        "    print(f\"Train images: {len(train_images)}, Val images: {len(val_images)}\")\n",
        "    print(f\"Wrote: {train_json}\")\n",
        "    print(f\"Wrote: {val_json}\")\n",
        "\n",
        "\n",
        "# Run the split\n",
        "split_coco_and_images(COCO_PATH, IMAGES_ROOT, TARGET_ROOT, VAL_RATIO, RANDOM_SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94ea63d3",
      "metadata": {},
      "source": [
        "## Step 2: Create Multi-class YOLO Labels (One Dataset for All Letters)\n",
        "\n",
        "We now convert the split COCO files into YOLO format, **preserving script modes**. The output\n",
        "structure will be:\n",
        "\n",
        "```text\n",
        "ASC_dataset2/\n",
        "  labels/\n",
        "    train/french/*.txt\n",
        "    train/german/*.txt\n",
        "    val/french/*.txt\n",
        "    val/german/*.txt\n",
        "```\n",
        "\n",
        "- Each `.txt` file contains multiple lines: `class_id cx cy w h`.\n",
        "- `class_id` is a YOLO index (0..N-1) derived from the COCO `categories`.\n",
        "- This is **multi-class**, keeping the distinct letters.\n",
        "\n",
        "Later, in YOLOv11 you can train **one letter at a time** by using the `classes=[index]`\n",
        "and `single_cls=True` options.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "70891327",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO labels created under: ASC_dataset2/labels/train\n",
            "Category mapping (COCO id -> YOLO index):\n",
            "  1 -> 0 : Aleph\n",
            "  2 -> 1 : He\n",
            "  3 -> 2 : Mem\n",
            "  4 -> 3 : Shin\n",
            "  5 -> 4 : Mem Sofit\n",
            "  6 -> 5 : Tav\n",
            "YOLO labels created under: ASC_dataset2/labels/val\n",
            "Category mapping (COCO id -> YOLO index):\n",
            "  1 -> 0 : Aleph\n",
            "  2 -> 1 : He\n",
            "  3 -> 2 : Mem\n",
            "  4 -> 3 : Shin\n",
            "  5 -> 4 : Mem Sofit\n",
            "  6 -> 5 : Tav\n"
          ]
        }
      ],
      "source": [
        "def coco_to_yolo_multiclass(image_root: Path, coco_json: Path):\n",
        "    \"\"\"Convert COCO annotations to YOLO txt labels (multi-class),\n",
        "    preserving script mode subdirectories (french/german).\n",
        "\n",
        "    image_root: e.g. ASC_dataset2/images/train\n",
        "    coco_json:  e.g. ASC_dataset2/annotations_train.json\n",
        "    \"\"\"\n",
        "    labels_root = Path(str(image_root).replace(\"images\", \"labels\"))\n",
        "    labels_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    with coco_json.open(\"r\") as f:\n",
        "        coco = json.load(f)\n",
        "\n",
        "    image_info = {img[\"id\"]: img for img in coco[\"images\"]}\n",
        "\n",
        "    # Build category_id -> YOLO class index\n",
        "    categories = sorted(coco[\"categories\"], key=lambda c: c[\"id\"])\n",
        "    cat_id_to_yolo = {cat[\"id\"]: idx for idx, cat in enumerate(categories)}\n",
        "\n",
        "    # Group annotations by image\n",
        "    anns_by_img = {}\n",
        "    for ann in coco[\"annotations\"]:\n",
        "        img_id = ann[\"image_id\"]\n",
        "        anns_by_img.setdefault(img_id, []).append(ann)\n",
        "\n",
        "    for img_id, anns in anns_by_img.items():\n",
        "        img = image_info[img_id]\n",
        "        fname = img[\"file_name\"]\n",
        "        width, height = img[\"width\"], img[\"height\"]\n",
        "\n",
        "        # Determine script mode by checking subdirs\n",
        "        script_mode_found = None\n",
        "        for script_mode in [\"french\", \"german\"]:\n",
        "            candidate = image_root / script_mode / fname\n",
        "            if candidate.exists():\n",
        "                script_mode_found = script_mode\n",
        "                break\n",
        "\n",
        "        if script_mode_found is None:\n",
        "            print(f\"WARNING: image {fname} not found under {image_root}/french or german.\")\n",
        "            continue\n",
        "\n",
        "        labels_dir = labels_root / script_mode_found\n",
        "        labels_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        stem = Path(fname).stem\n",
        "        label_path = labels_dir / f\"{stem}.txt\"\n",
        "\n",
        "        with label_path.open(\"w\") as lf:\n",
        "            for ann in anns:\n",
        "                x, y, w, h = ann[\"bbox\"]\n",
        "                cx = (x + w / 2) / width\n",
        "                cy = (y + h / 2) / height\n",
        "                nw = w / width\n",
        "                nh = h / height\n",
        "\n",
        "                class_id = cat_id_to_yolo[ann[\"category_id\"]]\n",
        "                lf.write(f\"{class_id} {cx:.6f} {cy:.6f} {nw:.6f} {nh:.6f}\\n\")\n",
        "\n",
        "    print(f\"YOLO labels created under: {labels_root}\")\n",
        "    print(\"Category mapping (COCO id -> YOLO index):\")\n",
        "    for cat in categories:\n",
        "        print(f\"  {cat['id']} -> {cat_id_to_yolo[cat['id']]} : {cat['name']}\")\n",
        "\n",
        "\n",
        "# Run for train and val splits\n",
        "coco_to_yolo_multiclass(TARGET_ROOT / \"images\" / \"train\", TARGET_ROOT / \"annotations_train.json\")\n",
        "coco_to_yolo_multiclass(TARGET_ROOT / \"images\" / \"val\",   TARGET_ROOT / \"annotations_val.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c06986d",
      "metadata": {},
      "source": [
        "## Step 3: Per-Letter COCO Files for Detectron2 (Single Letter per Model)\n",
        "\n",
        "Now we prepare **per-letter COCO files** so that Detectron2 can be trained on one letter at a time,\n",
        "similar to how YOLO can be trained with `classes=[i]`.\n",
        "\n",
        "For each COCO `category_id` (letter class), we create:\n",
        "\n",
        "- `ASC_dataset2/per_letter/train_cat_<ID>.json`\n",
        "- `ASC_dataset2/per_letter/val_cat_<ID>.json`\n",
        "\n",
        "Each of these files contains:\n",
        "- Only annotations where `category_id == <ID>`.\n",
        "- Only images that have at least one annotation of that letter.\n",
        "- A `categories` list with a **single entry**: that specific letter.\n",
        "\n",
        "When you register one of these in Detectron2, it will internally map that\n",
        "single category to class index 0, so you can use `NUM_CLASSES = 1` in your config.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "69fa2b48",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote per-letter COCO for category 1 (Aleph):\n",
            "  ASC_dataset2/per_letter/train_cat_1.json\n",
            "  ASC_dataset2/per_letter/val_cat_1.json\n",
            "Wrote per-letter COCO for category 2 (He):\n",
            "  ASC_dataset2/per_letter/train_cat_2.json\n",
            "  ASC_dataset2/per_letter/val_cat_2.json\n",
            "Wrote per-letter COCO for category 3 (Mem):\n",
            "  ASC_dataset2/per_letter/train_cat_3.json\n",
            "  ASC_dataset2/per_letter/val_cat_3.json\n",
            "Wrote per-letter COCO for category 4 (Shin):\n",
            "  ASC_dataset2/per_letter/train_cat_4.json\n",
            "  ASC_dataset2/per_letter/val_cat_4.json\n",
            "Wrote per-letter COCO for category 5 (Mem Sofit):\n",
            "  ASC_dataset2/per_letter/train_cat_5.json\n",
            "  ASC_dataset2/per_letter/val_cat_5.json\n",
            "Wrote per-letter COCO for category 6 (Tav):\n",
            "  ASC_dataset2/per_letter/train_cat_6.json\n",
            "  ASC_dataset2/per_letter/val_cat_6.json\n"
          ]
        }
      ],
      "source": [
        "def make_per_letter_coco_splits(base_train_json: Path,\n",
        "                                base_val_json: Path,\n",
        "                                target_root: Path):\n",
        "    \"\"\"Generate per-letter COCO files for all categories found in base_train_json.\n",
        "\n",
        "    Outputs go into target_root / \"per_letter\" as:\n",
        "      - train_cat_<ID>.json\n",
        "      - val_cat_<ID>.json\n",
        "    \"\"\"\n",
        "    per_letter_dir = target_root / \"per_letter\"\n",
        "    per_letter_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    with base_train_json.open(\"r\") as f:\n",
        "        train_coco = json.load(f)\n",
        "    with base_val_json.open(\"r\") as f:\n",
        "        val_coco = json.load(f)\n",
        "\n",
        "    categories = train_coco[\"categories\"]\n",
        "    cat_id_to_cat = {c[\"id\"]: c for c in categories}\n",
        "\n",
        "    # Helper: filter a COCO dict to a single category_id\n",
        "    def filter_to_cat(coco_dict, cat_id):\n",
        "        anns = [a for a in coco_dict[\"annotations\"] if a[\"category_id\"] == cat_id]\n",
        "        img_ids = {a[\"image_id\"] for a in anns}\n",
        "        imgs = [img for img in coco_dict[\"images\"] if img[\"id\"] in img_ids]\n",
        "        cat = cat_id_to_cat[cat_id]\n",
        "        return {\n",
        "            \"images\": imgs,\n",
        "            \"annotations\": anns,\n",
        "            \"categories\": [cat],\n",
        "        }\n",
        "\n",
        "    for cat in categories:\n",
        "        cat_id = cat[\"id\"]\n",
        "        name = cat.get(\"name\", f\"cat_{cat_id}\")\n",
        "\n",
        "        train_single = filter_to_cat(train_coco, cat_id)\n",
        "        val_single = filter_to_cat(val_coco, cat_id)\n",
        "\n",
        "        # Skip if there are no annotations for this cat in train/val\n",
        "        if len(train_single[\"annotations\"]) == 0 and len(val_single[\"annotations\"]) == 0:\n",
        "            print(f\"Skipping category {cat_id} ({name}): no annotations in train or val.\")\n",
        "            continue\n",
        "\n",
        "        out_train = per_letter_dir / f\"train_cat_{cat_id}.json\"\n",
        "        out_val = per_letter_dir / f\"val_cat_{cat_id}.json\"\n",
        "\n",
        "        with out_train.open(\"w\") as f:\n",
        "            json.dump(train_single, f, indent=4)\n",
        "        with out_val.open(\"w\") as f:\n",
        "            json.dump(val_single, f, indent=4)\n",
        "\n",
        "        print(f\"Wrote per-letter COCO for category {cat_id} ({name}):\")\n",
        "        print(f\"  {out_train}\")\n",
        "        print(f\"  {out_val}\")\n",
        "\n",
        "\n",
        "make_per_letter_coco_splits(\n",
        "    TARGET_ROOT / \"annotations_train.json\",\n",
        "    TARGET_ROOT / \"annotations_val.json\",\n",
        "    TARGET_ROOT,\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "measure_ratios",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
